#!/usr/bin/perl

# Program which compares a (deterministic) HMM with one inferred from data
# generated by the original

# The user needs to say where information about the two HMMs may be found.

# The formats for the two machines are not the same, alas...

# We calculate a bunch of numbers, in two categories.

# The first, and easiest, is the entropy of the true (causal) states
# conditional on the inferred states.  For that we need merely the two state
# sequences and some logs.

# The second is more tricky.  Each HMM specifies a distribution over observed
# sequences of (arbitrary) length.  We pick one, and compute the relative
# entropy of the true and the inferred distributions.  We do this as the
# entropy of the inferred relative to the true, as this is the expected
# number of _excess_ bits from using the inferred distribution in coding.

# We assume always a binary observational alphabet.


# To be used in conjunction with Kris's state-inference program.


# First argument is the name-base for the inferred-machine files
# The second is the name-base for the true machine files
# Third argument is the string length

$InferredNamesBase = shift(@ARGV);
$CausalNamesBase = shift(@ARGV);
$string_length = shift(@ARGV);


$TimeSeqFileName = $InferredNamesBase;
$CausalSeqFileName = $CausalNamesBase . "_stateseq";
$InferredSeqFileName = $InferredNamesBase . "_state_series";
$ResultsFileName = $InferredNamesBase . "_results";
$MachineFileName = $CausalNamesBase . "_machine";

# Build transition information

# First build the inferred state transition information

# Open the _results file for reading
open (RESULTS, $ResultsFileName) || die "Couldn't open $ResultsFileName: $!";
while (<RESULTS>) {
    # Get a line
    # Remember that by default the input line is read into $_, which is also
    # the default operand for chomp and split
    chomp;
    @ResultsLine = split;
    # Default splitting on whitespace
    # If the first word on the line is "State" then we're getting a state
    # number
    # i.e. the line looks like "State number: X"
    if ($ResultsLine[0] eq "State") {
	$InferredState = $ResultsLine[2];
	push(@InferredStatesList,$InferredState);
    } elsif ($ResultsLine[0] eq "distribution:") {
	# These lines look like "distribution: P(0) = X P(1) = Y", where X is
	# prob of 0, etc.
	# So X is word 3 (from 0), and Y is word 6
	$InferredZeroProb{$InferredState} = $ResultsLine[3];
	$InferredOneProb{$InferredState} = $ResultsLine[6];
    } elsif ($ResultsLine[0] eq "transitions:") {
	# These lines look like "transitions: T(0) = X T(0) = Y"
	$InferredZeroTrans{$InferredState} = $ResultsLine[3];
	$InferredOneTrans{$InferredState} = $ResultsLine[6];
    }
}
# Continue scanning until file is ended
close(RESULTS) || die "Can't close $ResultsFileName: $!";

# Handle the occasional "NULL" meaning no such state in the output
$InferredZeroTrans{"NULL"} = "NULL";
$InferredOneTrans{"NULL"} = "NULL";

# For the _machine file,
# States are given proper alphabetic labels
# Lines are as detailed below; we want those beginning "State", "Emits",
# and "Probability"
open(MACHINE,$MachineFileName) || die "Can't open $MachineFileName: $!";
while (<MACHINE>) {
    # Current line is set to $_, the default operand
    chomp;
    @MachineLine = split;
    # Default split on whitespace
    $FirstWord = $MachineLine[0];
    if ($FirstWord eq "State") {
	# These lines look like: "State X:", i.e., include a : after names
	$CausalState = $MachineLine[1];
	chop($CausalState);
	# Gets rid of the colon
	push(@CausalStatesList,$CausalState);
    } elsif ($FirstWord eq "Emits") {
	# Lines look like "Emits X with prob P and goes to Z"
	if ($MachineLine[1] == 0) {
	    $CausalZeroProb{$CausalState} = $MachineLine[4];
	    $CausalZeroTrans{$CausalState} = $MachineLine[8];
	} else {
	    $CausalOneProb{$CausalState} = $MachineLine[4];
	    $CausalOneTrans{$CausalState} = $MachineLine[8];
	}
    } elsif ($FirstWord eq "Probability") {
	$CausalProb{$CausalState} = $MachineLine[1];
    }
    else {
    }
# Continue scanning to end of file
}
close(MACHINE) || die "Couldn't close $MachineFileName: $!";

# We need to get the original time-series for comparative purposes
open(TIME_SEQ,$TimeSeqFileName) || die "Can't open $TimeSeqFileName: $!";
while (<TIME_SEQ>) {
    chomp;
    $TimeSeq .= $_;
}
close(TIME_SEQ) || die "Can't close $TimeSeqFileName: $!";


# Get the empirical probabilities
$time_seq_length = length($TimeSeq);
for ($i = 0; $i < ($time_seq_length - $string_length); $i++) {
    $string = substr($TimeSeq,$i,$string_length);
    $EmpWord{$string}++;
}


# Calculation of H[\CausalState|\InferredState]

# Read in causal state sequence
open(CAUSAL_SEQ,$CausalSeqFileName) || die "Can't open $CausalSeqFileName: $!";
while (<CAUSAL_SEQ>) {
    chomp;
    $CausalSequence .= $_;
}
close(CAUSAL_SEQ) || die "Can't close $CausalSeqFileName: $!";
# system("gzip $CausalSeqFileName");

# Read in inferred state sequence
open(INFERRED_SEQ,$InferredSeqFileName) || die "Can't open $InferredSeqFileName: $!";
while (<INFERRED_SEQ>) {
    chomp;
    $InferredSequenceRaw .= $_;
}
close(INFERRED_SEQ) || die "Can't close $InferredSeqFileName: $!";

# Now, the inferred sequence is stored as numbers separated by semi-colons,
# so we need to turn it into an array.
@InferredSequence = split(/;/,$InferredSequenceRaw);

# We need to know the total number of symbols; also, we need to make sure
# the two series have the same length
if ((scalar @InferredSequence) != length($CausalSequence)) {
    die "State sequences are of different lengths!";
    # Dying here is excessive and inconvenient; we should just output a warning
    # and skip calculating the equivocation.  After all, for the other
    # numbers, where we just need the state probabilities, we can get those
    # from other sources.
} else {
    $TotalCount = (scalar @InferredSequence);
}

# We need the conditional distribution of causal states given inferred
# states
# Store this in a hash of hashes (so I don't have to worry about what
# the alphabet is), call it %ConditionalCount
# Also keep track of how many times each inferred state is seen, in
# $InferredCount
# I've diverted all this to sub-routines.

&initialize_cond_prob_thingies;
&scan_for_cond_probs;
$ConditionalEntropy = &cond_counts_to_cond_probs();




# Invoke the subroutine to calculate relative entropy/KL-divergence and
# total variation
($KLDiv,$TotVar,$EmpDiv,$EmpVar,$SampFluc) = calc_relative_entropy();
$KL_rate = "Infinity";
$KL_rate = $KLDiv/$string_length unless ($KLDiv eq "Infinity");
$EmpDiv_rate = "Infinity";
$EmpDiv_rate = $EmpDiv/$string_length unless ($EmpDiv eq "Infinity");

$EffectiveCausalStates = @ObservedCausalStates;
$EffectiveInferred = @InferredStatesList;

$OutputFileName = $InferredNamesBase . "_comparison";
open(OUT, ">$OutputFileName") || die "Can't write to $OutputFileName: $!\n";
print OUT "Causal States Visited: $EffectiveCausalStates\n";
print OUT "Inferred States Visited: $EffectiveInferred\n";
print OUT "Divergence: $KLDiv bits over $string_length symbols\n";
print OUT "Rate: $KL_rate bits per symbol\n";
print OUT "Variation: $TotVar\n";
print OUT "Equivocation: $ConditionalEntropy bits\n";
print OUT "Empirical Divergence: $EmpDiv bits\n";
print OUT "Empirical Divergence Rate: $EmpDiv_rate bits per symbol\n";
print OUT "Empirical Variation: $EmpVar\n";
print OUT "Sampling Fluctuation: $SampFluc\n";
close(OUT) || die "Can't close $OutputFileName: $!\n";


# HERE ENDETH THE PROGRAM

sub log_2 {
    # Input is a positive real number
    # Output is its base-two logarithm
    return(log($_[0])/log(2.0));
}



sub calc_relative_entropy {

# Calculate the entropy of the inferred states' distribution for
# strings of length $string_length relative to that of the causal states.

# While we're at it, calculate the total-variation distance between
# the distributions.

# Entropy of supposed distribution Q relative to true distribution P is
# sum_{i}{P_i log(P_i/Q_i)}, with 0log(0/q) = 0 and plog(p/0) = infinity.
# The interpretation is that a code based on Q requires H(P) + D(Q||P)
# bits per symbol, whereas a true code based on P needs just H(P).
# This means we get infinitely penalized for saying that something isn't
# possible when it is, but oh well.

    @LStrings = ();
    $num_strings = 2**$string_length;

# Generate all possible strings of length L
    for ($i = 0; $i < $num_strings; $i++) {
	# Make $string = the binary version of $i
	$string = binary_of_number($i);
	# Add $string to the list of all L-strings
	@LStrings = (@LStrings, $string);
    }

# For each string of length L,
    foreach $string (@LStrings) {
	# Calculate the true, inferred and empirical probabilities
	$WordCausal = &causal_string_prob($string);
	$WordInf = &inferred_string_prob($string);
	$WordEmp = empirical_string_prob($string);

	if ($WordCausal > 0) {
	    if ($WordInf == 0) {
		# Set the relative entropy to infinity
		$RelativeEntropy = "Infinity";
	    }
	    elsif ($RelativeEntropy ne "Infinity") {
		$KLTerm = log_2($WordCausal/$WordInf);
		$KLTerm *= $WordCausal;
		$RelativeEntropy += $KLTerm;
	    }
	}
	if ($WordEmp > 0) {
	    if ($WordInf == 0) {
		# Set the relative entropy to infinite
		$EmpiricalDivergence = "Infinity";
	    }
	    elsif ($EmpiricalDivergence ne "Infinity") {
		$DivTerm += log_2($WordEmp) - log_2($WordInf);
		$DivTerm *= $WordEmp;
		$EmpiricalDivergence += $DivTerm;
	    }
	}
	$TotalVariation += abs($WordCausal - $WordInf);
	$EmpiricalVariation += abs($WordEmp - $WordInf);
	$SamplingFluctuation += abs($WordEmp - $WordCausal);
    }
    @Values = ($RelativeEntropy,$TotalVariation);
    push(@Values,$EmpiricalDivergence);
    push(@Values,$EmpiricalVariation);
    push(@Values,$SamplingFluctuation);
    return(@Values);
}

sub state_label {
    # Take in a number and return the corresponding letter symbol
    # on the assumption that number 0 corresponds to A, and so on up through
    # ASCII
    $state_number = $_[0];
    $state_symbol = chr(65 + $state_number);
    return($state_symbol);
}

sub binary_of_number {
    # Function that takes an integer, presumed less than 2**$string_length,
    # and gives its binary representation
    $number = $_[0];
    $binary_string = "";
    for ($j = $string_length-1;$j >= 0; $j--) {
	# Count down the powers of two
	$TwoPower = 2**$j;
	if ($number >= $TwoPower) {
	    # If the number is greater than that power,
	    # then subtract the power and record a 1 there
	    $binary_string .= "1";
	    $number -= $TwoPower;
	} else {
	    # Otherwise, record a zero and go on the next lower power
	    $binary_string .= "0";
	}
    }
    return($binary_string);
}

sub causal_string_prob {
    # Takes a string and returns its probability under the true machine.
    my($string,$prob,$word_length);
    $string = $_[0];

    $word_length = length($string);

    foreach $Causal (@CausalStatesList) {
	# For each causal state, find the probability of that string if started
	# from that state; record in $StringCondCausal
	$StringCondCausal = 1;
	$CurrentState = $Causal;
	for ($i = 0; $i < $word_length; $i++) {
	    $CurrentSymbol = substr($string,$i,1);
	    if ($CurrentSymbol == 0) {
		$StringCondCausal *= $CausalZeroProb{$CurrentState};
		$CurrentState = $CausalZeroTrans{$CurrentState};
	    } else {
		$StringCondCausal *= $CausalOneProb{$CurrentState};
		$CurrentState = $CausalOneTrans{$CurrentState};
	    }
	}
	# Average over all states
	$prob += $StringCondCausal * $CausalProb{$Causal};
    }
    return($prob);
}

sub inferred_string_prob {
    # Calculate the probability of a string under the inferred machine
    my($string,$prob,$i,$CurrentState,$word_length);
    $string = $_[0];
    $word_length = length($string);

    foreach $Inferred (keys %InferredProb) {
	$StringCondInferred = 1;
	# For each inferred state,
	# Caclulate the probability of that string if started from that
	# state
	$CurrentState = $Inferred;
	for ($i = 0; $i < $word_length; $i++) {
	    $CurrentSymbol = substr($string,$i,1);
	    if ($CurrentSymbol == 0) {
		$StringCondInferred *= $InferredZeroProb{$CurrentState};
		$CurrentState = $InferredZeroTrans{$CurrentState};
	    } else {
		$StringCondInferred *= $InferredOneProb{$CurrentState};
		$CurrentState = $InferredOneTrans{$CurrentState};
	    }
	}
	# Record in temporary $StringCondInferred
	# Average over all states
	$prob += $StringCondInferred * $InferredProb{$Inferred};
    }
    return($prob);
}

sub empirical_string_prob {
    # Calculate the empirical probability of a string
    my($string,$prob,$word_length);
    $string = $_[0];
    $word_length = length($string);
    
    $denominator = $time_seq_length - $word_length;
    $prob = 0;
    $prob = $EmpWord{$string}/$denominator if ($EmpWord{$string});
    # %EmpWord is defined only for keys that actually occur in the data.
    return($prob);
}


sub initialize_cond_prob_thingies {
    # Initialized %ConditionalCount and %CondProb
    foreach $Inferred (@InferredStatesList) {
	$HaveInferred{$Inferred} = 0;
	$InferredCount{$Inferred} = 0;
	$InferredProb{$Inferred} = 0;
	$rec = {};
	$rec2 = {};
	$ConditionalCount{$Inferred} = $rec;
	$CondProb{$Inferred} = $rec2;
	foreach $Causal (@CausalStatesList) {
	    ($key, $Count) = ($Causal, 0);
	    ($key2, $Prob) = ($Causal, 0);
	    $rec->{$key} = $Count;
	    $rec2->{$key2} = $Prob;
	}
    }

    foreach $Causal (@CausalStatesList) {
	$HaveSeen{$Causal} = 0;
    }
}

sub scan_for_cond_probs{
    # Scan over sequence
    for ($i = 0; $i < $TotalCount; $i++) {
	$Inferred = $InferredSequence[$i];
	$Causal = substr($CausalSequence,$i,1);
	# Get the characters at the ith position (counting from 0) of the
	# series.
	# Leave the series alone --- too much work to be constantly lopping
	# things off them
	# If $Inferred = ?, then we've not synchronized yet, and rather than
	# deal with synchronization states, we'll just ignore that position
	if ($Inferred ne "\?") {
	    $ConditionalCount{$Inferred}{$Causal}++;
	    $InferredCount{$Inferred}++;
	    # Record that we have seen this causal state
	    if ($HaveSeen{$Causal} == 0) {
		push(@ObservedCausalStates,$Causal);
		$HaveSeen{$Causal} = 1;
	    }
	    if ($HaveInferred{$Inferred} == 0) {
		push(@SeenInferred,$Inferred);
		$HaveInferred{$Inferred} = 1;
	    }
	} else {
	    $TotalCounts--;
	    # Decrement our count of the total number of symbols, since
	    # we're not counting these
	}
    }
}

sub cond_counts_to_cond_probs {
    # Convert counts to probabilities.
    # Since searching through a hash may be slow, I'm combining this with
    # manipulating the probabilities so as to get the conditional entropy for
    # each inferred state and the overall conditional entropy
    my($ConditionalEntropy);

    $ConditionalEntropy = 0;
    
    foreach $Inferred (@InferredStatesList) {
	$InferredProb{$Inferred} = $InferredCount{$Inferred}/$TotalCount;
	$CondEnt{$Inferred} = 0;
	foreach $Causal (@ObservedCausalStates) {
	    # with @ObservedCausalStates ought to
	    if ($InferredCount{$Inferred} > 0) {
		$CondProb{$Inferred}{$Causal} = $ConditionalCount{$Inferred}{$Causal}/$InferredCount{$Inferred};
	    } else {
		$CondProb{$Inferred}{$Causal} = 0;
	    }
	    if ($CondProb{$Inferred}{$Causal} > 0) {
		$CondEnt{$Inferred} -= $CondProb{$Inferred}{$Causal} * log_2($CondProb{$Inferred}{$Causal});
	    }
	}
	$ConditionalEntropy += $InferredProb{$Inferred} * $CondEnt{$Inferred};
    }
    return($ConditionalEntropy);
}
